{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdml_client in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (1.2.14)\n",
      "Requirement already satisfied: boto3 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from mdml_client) (1.18.44)\n",
      "Requirement already satisfied: jsonschema in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from mdml_client) (3.2.0)\n",
      "Requirement already satisfied: confluent-kafka in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from mdml_client) (1.7.0)\n",
      "Requirement already satisfied: pandas in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from mdml_client) (1.3.3)\n",
      "Requirement already satisfied: requests in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from mdml_client) (2.26.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from boto3->mdml_client) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.44 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from boto3->mdml_client) (1.21.44)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from boto3->mdml_client) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from botocore<1.22.0,>=1.21.44->boto3->mdml_client) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from botocore<1.22.0,>=1.21.44->boto3->mdml_client) (1.26.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.44->boto3->mdml_client) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from jsonschema->mdml_client) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from jsonschema->mdml_client) (58.0.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from jsonschema->mdml_client) (21.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from pandas->mdml_client) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from pandas->mdml_client) (2021.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from requests->mdml_client) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from requests->mdml_client) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jelias/miniconda3/envs/mdml/lib/python3.8/site-packages (from requests->mdml_client) (2.0.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install mdml_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import mdml_client as mdml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDML Producing Data\n",
    "\n",
    "When a client produces data with the MDML, the data is streamed to an underlying Kafka topic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {\n",
    "    'time': time.time(), \n",
    "    'int1': 3,\n",
    "    'int2': 4,\n",
    "    'int3': 5\n",
    "}\n",
    "schema = mdml.create_schema(example_data, \"Example schema\", \"schema for example notebook\")\n",
    "producer = mdml.kafka_mdml_producer(\n",
    "    topic = \"mdml-example-dict\",\n",
    "    schema = schema,\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "producer.produce(example_data)\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDML Consuming Data\n",
    "\n",
    "When consuming data from the MDML platform, data are read from Kafka topics. A consumer's `.consume()` method returns a generator which yields a result for every data message produced on the corresponding topic. The group parameter is used by the Kafka to coordinate groups of consumers such that each message streamed to a topic is only received by the consumer group once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer loop will exit after 300.0 seconds without receiving a message or with Ctrl+C\n",
      "{'topic': 'mdml-example-dict', 'value': {'time': 1645128376.6569948, 'int1': 3, 'int2': 4, 'int3': 5, 'mdml_time': 1645128376.6648843}}\n"
     ]
    }
   ],
   "source": [
    "consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = [\"mdml-example-dict\"],\n",
    "    group = \"abc\", # create a unique group id here\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "for msg in consumer.consume():\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Files via MDML\n",
    "\n",
    "The MDML takes two approaches to streaming large files. One is by chunking and the other we call \"coat-checking\". In chunking, a large file is broken up into smaller chunks that are sent directly to the MDML. We will only demonstrate the chunking method here. The second method of \"coat-checking\" uses an S3 bucket to upload files. At the same time, a message describing the location and some metadata about the file is sent to the MDML. A consumer could then download the file from the specified S3 bucket location in the message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_file = \"large_file.txt\" # ~20MB\n",
    "producer = mdml.kafka_mdml_producer(\n",
    "    topic = \"mdml-example-file\",\n",
    "    schema = mdml.multipart_schema, # using MDML's pre-defined schema for chunking\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "i=0\n",
    "for chunk in mdml.chunk_file(large_file, 750000): # chunk size of 500,000 Bytes\n",
    "    producer.produce(chunk)\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(\"flush\")\n",
    "        producer.flush() # flush every 50 chunks\n",
    "print(\"final flush\")\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = [\"mdml-example-file\"],\n",
    "    group = \"abc\", # create a unique group id here\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "for msg in consumer.consume_chunks(): # the message returned is the filepath that the chunked file was written to\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDML Experiments\n",
    "\n",
    "The MDML service implements functionality to create user-defined experiments. In short, an experiment aggregates data from multiple topics to capture any produced messages on the given topics. All messages produced between the start and stop of the experiment will be recorded in a separate experiment topic as well as a JSON file for upload to the Argonne Data Cloud.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment topics\n",
    "experiment_topics = [\n",
    "    \"mdml-test-experiment-sensor1\",\n",
    "    \"mdml-test-experiment-sensor2\",\n",
    "    \"mdml-test-experiment-sensor3\",\n",
    "]\n",
    "# MDML connection configuration\n",
    "producer_config = {\n",
    "    \"kafka_host\": \"100.26.16.4\",\n",
    "    \"schema_host\": \"100.26.16.4\"\n",
    "}\n",
    "# Start experiment\n",
    "experiment_id = \"replay_test_2\" \n",
    "exp = mdml.start_experiment(\n",
    "    id = experiment_id, \n",
    "    topics = experiment_topics,\n",
    "    producer_kwargs = producer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a function to produce random data\n",
    "def random_data():\n",
    "    dat = {\n",
    "        \"time\": time.time(),\n",
    "        \"data\": random.randrange(0,100)\n",
    "    }\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data schema\n",
    "data_schema = mdml.create_schema(random_data(), title=\"example schema\", descr=\"schema for the example notebook\")\n",
    "# Create data producers\n",
    "producer1 = mdml.kafka_mdml_producer(\"mdml-test-experiment-sensor1\", schema=data_schema, **producer_config)\n",
    "producer2 = mdml.kafka_mdml_producer(\"mdml-test-experiment-sensor2\", schema=data_schema, **producer_config)\n",
    "producer3 = mdml.kafka_mdml_producer(\"mdml-test-experiment-sensor3\", schema=data_schema, **producer_config)\n",
    "# Perform the experiment\n",
    "for _ in range(5):    \n",
    "    producer1.produce(random_data())\n",
    "    producer2.produce(random_data())\n",
    "    producer3.produce(random_data())\n",
    "    time.sleep(3)\n",
    "# Flush producers\n",
    "producer1.flush()\n",
    "producer2.flush()\n",
    "producer3.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the experiment\n",
    "mdml.stop_experiment(\n",
    "    id = experiment_id,\n",
    "    producer_kwargs = producer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdml.get_experiment_data(\"replay_test_2\",\"YOUR_ADC_TOKEN_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuncX and MDML\n",
    "\n",
    "### Registering a function\n",
    "This tutorial function sums up integers and produces a new message with the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f4461f7-a4e8-4c4d-addc-f20cf447b409\n"
     ]
    }
   ],
   "source": [
    "from funcx.sdk.client import FuncXClient\n",
    "fxc = FuncXClient()\n",
    "\n",
    "def addition_func(params):\n",
    "    import time\n",
    "    import mdml_client as mdml\n",
    "    values = params['addition_values']\n",
    "    consumer = mdml.kafka_mdml_consumer(\n",
    "        topics = [params['data_topic'], params['control_topic']],\n",
    "        group = \"mdml-testing-funcx-tutorial\")\n",
    "    example_result = {\n",
    "        'time': time.time(),\n",
    "        'int1': 1,\n",
    "        'int2': 2,\n",
    "        'int3': 3,\n",
    "        'sum': 6,\n",
    "        'worker_id': 0\n",
    "    }\n",
    "    schema = mdml.create_schema(example_result, \n",
    "                                title='mdml-testing-funcx-tutorial-sum', \n",
    "                                descr='Tutorial for deploying FuncX function with MDML')\n",
    "    result_producer = mdml.kafka_mdml_producer(\n",
    "        topic = \"mdml-testing-funcx-tutorial-sum\",\n",
    "        schema = schema\n",
    "    )\n",
    "    for msg in consumer.consume(overall_timeout=600):\n",
    "        if msg['topic'] == params['data_topic']:\n",
    "            result = msg['value']\n",
    "            result['worker_id'] = params['worker_id']\n",
    "            sum = 0\n",
    "            for val in values:\n",
    "                sum += msg['value'][val]\n",
    "            result['sum'] = sum\n",
    "            result_producer.produce(result)\n",
    "            result_producer.flush()\n",
    "        else:\n",
    "            break\n",
    "    consumer.close()\n",
    "\n",
    "# Function parameters\n",
    "params = {\n",
    "    'data_topic': 'mdml-testing-funcx-tutorial-data',\n",
    "    'control_topic': 'mdml-testing-funcx-tutorial-stop',\n",
    "    'addition_values': ['int1','int2','int3'],\n",
    "    'worker_id': 1\n",
    "}\n",
    "\n",
    "func_id = fxc.register_function(addition_func, description=\"Tutorial function for FuncX and MDML\")\n",
    "print(func_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most recent UUID - Feb 1st, 2022 9:22AM\n",
    "func_id = '5f4461f7-a4e8-4c4d-addc-f20cf447b409'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "press enter to check status again\n",
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "press enter to check status again\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "press enter to check status again\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "press enter to check status again\n",
      "Task is pending due to running\n",
      "Task is pending due to running\n",
      "Task is pending due to running\n",
      "press enter to check status again\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_483/615859666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"press enter to check status again\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mdml/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mdml/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "num_workers = 3\n",
    "tasks = []\n",
    "\n",
    "for i in range(num_workers):\n",
    "    params = {\n",
    "        'data_topic': 'mdml-testing-funcx-tutorial-data',\n",
    "        'control_topic': 'mdml-testing-funcx-tutorial-stop',\n",
    "        'addition_values': ['int1','int2','int3'],\n",
    "        'worker_id': i\n",
    "    }\n",
    "    endp_id = 'fa1a5d62-86f1-4761-87d5-0a2976a3e1c5' # public mdml endpoint on GPU server\n",
    "    tasks.append(fxc.run(params, function_id=func_id, endpoint_id=endp_id))\n",
    "\n",
    "while True:\n",
    "    for task in tasks:\n",
    "        try:\n",
    "            result = fxc.get_result(task)\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    input(f\"press enter to check status again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer loop will run indefinitely until a Ctrl+C\n",
      "{'topic': 'mdml-testing-funcx-tutorial-sum', 'value': {'time': 1643651363.290894, 'int1': 26, 'int2': 8, 'int3': 61, 'mdml_time': 1643651364.3562765, 'sum': 95}}\n",
      "{'topic': 'mdml-testing-funcx-tutorial-sum', 'value': {'time': 1643651369.3361378, 'int1': 97, 'int2': 23, 'int3': 71, 'mdml_time': 1643651369.4128666, 'sum': 191}}\n",
      "{'topic': 'mdml-testing-funcx-tutorial-sum', 'value': {'time': 1643651394.1517346, 'int1': 8, 'int2': 2, 'int3': 21, 'mdml_time': 1643651395.2494736, 'sum': 31}}\n"
     ]
    }
   ],
   "source": [
    "# Consume function results\n",
    "consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = ['mdml-testing-funcx-tutorial-sum'],\n",
    "    group = \"mdml-testing-funcx-tutorial\")\n",
    "for msg in consumer.consume(overall_timeout=-1):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop FuncX worker\n",
    "producer = mdml.kafka_mdml_producer(topic=\"mdml-testing-funcx-tutorial-stop\",\n",
    "             schema=mdml.stop_funcx_schema)\n",
    "producer.produce({'stop':True})\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdml",
   "language": "python",
   "name": "mdml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
