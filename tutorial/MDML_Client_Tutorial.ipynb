{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdml_client in /home/jelias/miniconda3/lib/python3.8/site-packages (1.1.82)\n",
      "Requirement already satisfied: paho-mqtt in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (3.4.1)\n",
      "Requirement already satisfied: pandas in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (1.2.4)\n",
      "Requirement already satisfied: opencv-python in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (4.1.2.30)\n",
      "Requirement already satisfied: funcx in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (0.2.3)\n",
      "Requirement already satisfied: confluent-kafka in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (1.7.0)\n",
      "Requirement already satisfied: boto3 in /home/jelias/miniconda3/lib/python3.8/site-packages (from mdml_client) (1.17.94)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from matplotlib->mdml_client) (8.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jelias/miniconda3/lib/python3.8/site-packages (from matplotlib->mdml_client) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from matplotlib->mdml_client) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/jelias/miniconda3/lib/python3.8/site-packages (from matplotlib->mdml_client) (1.19.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from matplotlib->mdml_client) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jelias/miniconda3/lib/python3.8/site-packages (from matplotlib->mdml_client) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jelias/miniconda3/lib/python3.8/site-packages (from pandas->mdml_client) (2021.1)\n",
      "Requirement already satisfied: pyzmq>=22.0.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (22.1.0)\n",
      "Requirement already satisfied: fair-research-login in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (0.2.0)\n",
      "Requirement already satisfied: texttable in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (1.6.3)\n",
      "Requirement already satisfied: python-daemon in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (2.24.0)\n",
      "Requirement already satisfied: typer>=0.3.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (0.3.2)\n",
      "Requirement already satisfied: parsl>=1.1.0a0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (1.1.0)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (3.2.0)\n",
      "Requirement already satisfied: dill>=0.3 in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (0.3.4)\n",
      "Requirement already satisfied: configobj in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (5.0.6)\n",
      "Requirement already satisfied: packaging in /home/jelias/miniconda3/lib/python3.8/site-packages (from funcx->mdml_client) (20.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from boto3->mdml_client) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from boto3->mdml_client) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.94 in /home/jelias/miniconda3/lib/python3.8/site-packages (from boto3->mdml_client) (1.20.94)\n",
      "Requirement already satisfied: six>=1.5 in /home/jelias/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->mdml_client) (1.15.0)\n",
      "Requirement already satisfied: globus-sdk>=1.5.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from fair-research-login->funcx->mdml_client) (2.0.1)\n",
      "Requirement already satisfied: lockfile>=0.10 in /home/jelias/miniconda3/lib/python3.8/site-packages (from python-daemon->funcx->mdml_client) (0.12.2)\n",
      "Requirement already satisfied: docutils in /home/jelias/miniconda3/lib/python3.8/site-packages (from python-daemon->funcx->mdml_client) (0.17.1)\n",
      "Requirement already satisfied: setuptools in /home/jelias/miniconda3/lib/python3.8/site-packages (from python-daemon->funcx->mdml_client) (50.3.1.post20201107)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jelias/miniconda3/lib/python3.8/site-packages (from requests>=2.20.0->funcx->mdml_client) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jelias/miniconda3/lib/python3.8/site-packages (from requests>=2.20.0->funcx->mdml_client) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jelias/miniconda3/lib/python3.8/site-packages (from requests>=2.20.0->funcx->mdml_client) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from requests>=2.20.0->funcx->mdml_client) (1.25.11)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from typer>=0.3.0->funcx->mdml_client) (7.1.2)\n",
      "Requirement already satisfied: paramiko in /home/jelias/miniconda3/lib/python3.8/site-packages (from parsl>=1.1.0a0->funcx->mdml_client) (2.7.2)\n",
      "Requirement already satisfied: psutil>=5.5.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from parsl>=1.1.0a0->funcx->mdml_client) (5.8.0)\n",
      "Requirement already satisfied: tblib in /home/jelias/miniconda3/lib/python3.8/site-packages (from parsl>=1.1.0a0->funcx->mdml_client) (1.7.0)\n",
      "Requirement already satisfied: typing-extensions in /home/jelias/miniconda3/lib/python3.8/site-packages (from parsl>=1.1.0a0->funcx->mdml_client) (3.10.0.0)\n",
      "Requirement already satisfied: typeguard>=2.10 in /home/jelias/miniconda3/lib/python3.8/site-packages (from parsl>=1.1.0a0->funcx->mdml_client) (2.12.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from jsonschema>=3.2.0->funcx->mdml_client) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/jelias/miniconda3/lib/python3.8/site-packages (from jsonschema>=3.2.0->funcx->mdml_client) (21.2.0)\n",
      "Requirement already satisfied: pyjwt[crypto]<2.0.0,>=1.5.3 in /home/jelias/miniconda3/lib/python3.8/site-packages (from globus-sdk>=1.5.0->fair-research-login->funcx->mdml_client) (1.7.1)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from paramiko->parsl>=1.1.0a0->funcx->mdml_client) (1.4.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/jelias/miniconda3/lib/python3.8/site-packages (from paramiko->parsl>=1.1.0a0->funcx->mdml_client) (3.2.1)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/jelias/miniconda3/lib/python3.8/site-packages (from paramiko->parsl>=1.1.0a0->funcx->mdml_client) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /home/jelias/miniconda3/lib/python3.8/site-packages (from pynacl>=1.0.1->paramiko->parsl>=1.1.0a0->funcx->mdml_client) (1.14.3)\n",
      "Requirement already satisfied: pycparser in /home/jelias/miniconda3/lib/python3.8/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko->parsl>=1.1.0a0->funcx->mdml_client) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install mdml_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import mdml_client as mdml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDML Producing Data\n",
    "\n",
    "When a client produces data with the MDML, the data is streamed to an underlying Kafka topic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {\n",
    "    'time': time.time(), \n",
    "    'int1': 3,\n",
    "    'int2': 4,\n",
    "    'int3': 5\n",
    "}\n",
    "schema = mdml.create_schema(example_data, \"Example schema\", \"schema for example notebook\")\n",
    "producer = mdml.kafka_mdml_producer(\n",
    "    topic = \"mdml-example-dict\",\n",
    "    schema = schema,\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "producer.produce(example_data)\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDML Consuming Data\n",
    "\n",
    "When consuming data from the MDML platform, data are read from Kafka topics. A consumer's `.consume()` method returns a generator which yields a result for every data message produced on the corresponding topic. The group parameter is used by the Kafka to coordinate groups of consumers such that each message streamed to a topic is only received by the consumer group once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer loop will exit after 300.0 seconds without receiving a message or with Ctrl+C\n",
      "{'topic': 'mdml-example-dict', 'value': {'time': 1645128376.6569948, 'int1': 3, 'int2': 4, 'int3': 5, 'mdml_time': 1645128376.6648843}}\n"
     ]
    }
   ],
   "source": [
    "consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = [\"mdml-example-dict\"],\n",
    "    group = \"abc\", # create a unique group id here\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "for msg in consumer.consume():\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Files via MDML\n",
    "\n",
    "The MDML takes two approaches to streaming large files. One is by chunking and the other we call \"coat-checking\". In chunking, a large file is broken up into smaller chunks that are sent directly to the MDML. We will only demonstrate the chunking method here. The second method of \"coat-checking\" uses an S3 bucket to upload files. At the same time, a message describing the location and some metadata about the file is sent to the MDML. A consumer could then download the file from the specified S3 bucket location in the message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_file = \"large_file.txt\" # ~20MB\n",
    "producer = mdml.kafka_mdml_producer(\n",
    "    topic = \"mdml-example-file\",\n",
    "    schema = mdml.multipart_schema, # using MDML's pre-defined schema for chunking\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "i=0\n",
    "for chunk in mdml.chunk_file(large_file, 750000): # chunk size of 500,000 Bytes\n",
    "    producer.produce(chunk)\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(\"flush\")\n",
    "        producer.flush() # flush every 50 chunks\n",
    "print(\"final flush\")\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = [\"mdml-example-file\"],\n",
    "    group = \"abc\", # create a unique group id here\n",
    "    kafka_host = '100.26.16.4',\n",
    "    schema_host = '100.26.16.4'\n",
    ")\n",
    "for msg in consumer.consume_chunks(): # the message returned is the filepath that the chunked file was written to\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDML Experiments\n",
    "\n",
    "The MDML service implements functionality to create user-defined experiments. In short, an experiment aggregates data from multiple topics to capture any produced messages on the given topics. All messages produced between the start and stop of the experiment will be recorded in a separate experiment topic as well as a JSON file for upload to the Argonne Data Cloud.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started\n"
     ]
    }
   ],
   "source": [
    "# Define experiment topics\n",
    "experiment_topics = [\n",
    "    \"mdml-test-experiment-sensor1\",\n",
    "    \"mdml-test-experiment-sensor2\",\n",
    "    \"mdml-test-experiment-sensor3\",\n",
    "]\n",
    "# MDML connection configuration\n",
    "producer_config = {\n",
    "    \"kafka_host\": \"100.26.16.4\",\n",
    "    \"schema_host\": \"100.26.16.4\"\n",
    "}\n",
    "# Start experiment\n",
    "experiment_id = \"replay_tutorial\" \n",
    "exp = mdml.start_experiment(\n",
    "    id = experiment_id, \n",
    "    topics = experiment_topics,\n",
    "    producer_kwargs = producer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a function to produce random data\n",
    "def random_data(i):\n",
    "    dat = {\n",
    "        \"time\": time.time(),\n",
    "        \"data\": random.randrange(0,100),\n",
    "        \"msg_id\": i\n",
    "    }\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1645206590.345|MAXPOLL|rdkafka#consumer-6| [thrd:main]: Application maximum poll interval (300000ms) exceeded by 410ms (adjust max.poll.interval.ms for long-running message processing): leaving group\n"
     ]
    }
   ],
   "source": [
    "# Generate data schema\n",
    "data_schema = mdml.create_schema(random_data(1), title=\"example schema\", descr=\"schema for the example notebook\")\n",
    "# Create data producers\n",
    "producer1 = mdml.kafka_mdml_producer(\"mdml-test-experiment-sensor1\", schema=data_schema, **producer_config)\n",
    "producer2 = mdml.kafka_mdml_producer(\"mdml-test-experiment-sensor2\", schema=data_schema, **producer_config)\n",
    "producer3 = mdml.kafka_mdml_producer(\"mdml-test-experiment-sensor3\", schema=data_schema, **producer_config)\n",
    "# Perform the experiment\n",
    "for i in range(5):    \n",
    "    producer1.produce(random_data(i))\n",
    "    producer2.produce(random_data(i))\n",
    "    producer3.produce(random_data(i))\n",
    "    time.sleep(3)\n",
    "# Flush producers\n",
    "producer1.flush()\n",
    "producer2.flush()\n",
    "producer3.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment stopped\n"
     ]
    }
   ],
   "source": [
    "# Stop the experiment\n",
    "mdml.stop_experiment(\n",
    "    id = experiment_id,\n",
    "    producer_kwargs = producer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaying an experiment\n",
    "\n",
    "After an experiment has been started and stop, it can be replayed. During a replay, all messages streamed to the experiment's configured topics will be re-streamed down those topics. This is useful for debugging ML code or for training and testing new models on a digital twin. One important note on the consumer for this example: if the consumer group that is specified has not already consumed the original experiment messages, they will be printed __in addition__ to the new replay messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer loop will run indefinitely until a Ctrl+C\n",
      "{'topic': 'mdml-test-experiment-sensor2', 'value': {'time': 1645206569.237449, 'data': 49, 'msg_id': 0, 'mdml_time': 1645207561.9636014}}\n",
      "{'topic': 'mdml-test-experiment-sensor1', 'value': {'time': 1645206569.1522157, 'data': 89, 'msg_id': 0, 'mdml_time': 1645207560.972872}}\n",
      "{'topic': 'mdml-test-experiment-sensor3', 'value': {'time': 1645206569.328619, 'data': 52, 'msg_id': 0, 'mdml_time': 1645207562.9689975}}\n",
      "{'topic': 'mdml-test-experiment-sensor1', 'value': {'time': 1645206572.4201186, 'data': 61, 'msg_id': 1, 'mdml_time': 1645207564.2407699}}\n",
      "{'topic': 'mdml-test-experiment-sensor3', 'value': {'time': 1645206572.4241636, 'data': 56, 'msg_id': 1, 'mdml_time': 1645207564.2486012}}\n",
      "{'topic': 'mdml-test-experiment-sensor2', 'value': {'time': 1645206572.4219654, 'data': 1, 'msg_id': 1, 'mdml_time': 1645207564.2450778}}\n",
      "{'topic': 'mdml-test-experiment-sensor1', 'value': {'time': 1645206575.4267747, 'data': 91, 'msg_id': 2, 'mdml_time': 1645207567.247416}}\n",
      "{'topic': 'mdml-test-experiment-sensor3', 'value': {'time': 1645206575.4302154, 'data': 70, 'msg_id': 2, 'mdml_time': 1645207567.2552307}}\n",
      "{'topic': 'mdml-test-experiment-sensor2', 'value': {'time': 1645206575.4286542, 'data': 14, 'msg_id': 2, 'mdml_time': 1645207567.2517333}}\n",
      "{'topic': 'mdml-test-experiment-sensor1', 'value': {'time': 1645206578.4322035, 'data': 47, 'msg_id': 3, 'mdml_time': 1645207570.2528522}}\n",
      "{'topic': 'mdml-test-experiment-sensor3', 'value': {'time': 1645206578.4360979, 'data': 34, 'msg_id': 3, 'mdml_time': 1645207570.2606745}}\n",
      "{'topic': 'mdml-test-experiment-sensor2', 'value': {'time': 1645206578.4346914, 'data': 71, 'msg_id': 3, 'mdml_time': 1645207570.2571754}}\n",
      "{'topic': 'mdml-test-experiment-sensor1', 'value': {'time': 1645206581.4384558, 'data': 82, 'msg_id': 4, 'mdml_time': 1645207573.2591069}}\n",
      "{'topic': 'mdml-test-experiment-sensor2', 'value': {'time': 1645206581.4390783, 'data': 14, 'msg_id': 4, 'mdml_time': 1645207573.2631054}}\n",
      "{'topic': 'mdml-test-experiment-sensor3', 'value': {'time': 1645206581.4394512, 'data': 29, 'msg_id': 4, 'mdml_time': 1645207573.266456}}\n"
     ]
    }
   ],
   "source": [
    "# First we will make a list of the topics used in the experiment\n",
    "topics = [\n",
    "    \"mdml-test-experiment-sensor1\",\n",
    "    \"mdml-test-experiment-sensor2\",\n",
    "    \"mdml-test-experiment-sensor3\"\n",
    "]\n",
    "# Next create a consumer to listen for the replayed messages\n",
    "replay_consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = topics,\n",
    "    group = \"abc\",\n",
    "    kafka_host = \"100.26.16.4\",\n",
    "    schema_host = \"100.26.16.4\"\n",
    ")\n",
    "# Start the replay with the MDML's Replay service\n",
    "mdml.replay_experiment(experiment_id, producer_kwargs=producer_config)\n",
    "# Starting the consumer\n",
    "for msg in replay_consumer.consume(overall_timeout=-1):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuncX and MDML\n",
    "\n",
    "The MDML pairs nicely with FuncX, a function as a service (FaaS) platform, to enable on-demand analyses. A FuncX endpoint has been created (endpoint ID below) that can be used to run any arbitrary Python code. Using the MDML client, you can create deployable functions to act on streaming data. These functions can then produce analysis results or even new operating conditions for an experiment back to the MDML.    \n",
    "\n",
    "### Registering a function\n",
    "First, we need to create a simple function that sums up integers and produces a new message with the result. This function is then registered with the FuncX service to receive a function ID that will be used to deploy the functions. Since this function has already been registered, the following cell cannot be run but shows the function's code for a better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from funcx.sdk.client import FuncXClient\n",
    "fxc = FuncXClient()\n",
    "\n",
    "def addition_func(params):\n",
    "    # FuncX functions require modules be imported (and installed on the endpoint)\n",
    "    import time\n",
    "    import mdml_client as mdml\n",
    "    values = params['addition_values']\n",
    "    # Create a consumer to listen for messages on a data topic and a control topic\n",
    "    consumer = mdml.kafka_mdml_consumer(\n",
    "        topics = [params['data_topic'], params['control_topic']],\n",
    "        group = \"mdml-testing-funcx-tutorial\")\n",
    "    # Create a schema for the returned results with an example dictionary \n",
    "    example_result = {\n",
    "        'time': time.time(),\n",
    "        'int1': 1,\n",
    "        'int2': 2,\n",
    "        'int3': 3,\n",
    "        'sum': 6,\n",
    "        'worker_id': 0\n",
    "    }\n",
    "    schema = mdml.create_schema(example_result, \n",
    "                                title='mdml-testing-funcx-tutorial-sum', \n",
    "                                descr='Tutorial for deploying FuncX function with MDML')\n",
    "    # Create a producer to stream the results with the schema\n",
    "    result_producer = mdml.kafka_mdml_producer(\n",
    "        topic = \"mdml-testing-funcx-tutorial-sum\",\n",
    "        schema = schema\n",
    "    )\n",
    "    # Start the consumer loop\n",
    "    for msg in consumer.consume(overall_timeout=600):\n",
    "        # If the message is on the data topic, sum values and produce a result\n",
    "        if msg['topic'] == params['data_topic']:\n",
    "            result = msg['value']\n",
    "            result['worker_id'] = params['worker_id']\n",
    "            sum = 0\n",
    "            for val in values:\n",
    "                sum += msg['value'][val]\n",
    "            result['sum'] = sum\n",
    "            result_producer.produce(result)\n",
    "            result_producer.flush()\n",
    "        # Else the message is from the control topic, stop the consumer loop and exit\n",
    "        else:\n",
    "            break\n",
    "    consumer.close()\n",
    "\n",
    "# Function parameters\n",
    "params = {\n",
    "    'data_topic': 'mdml-testing-funcx-tutorial-data',\n",
    "    'control_topic': 'mdml-testing-funcx-tutorial-stop',\n",
    "    'addition_values': ['int1','int2','int3'],\n",
    "    'worker_id': 1\n",
    "}\n",
    "\n",
    "func_id = fxc.register_function(addition_func, description=\"Tutorial function for FuncX and MDML\")\n",
    "print(func_id)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell is used to store the most current version of the FuncX function ID\n",
    "\n",
    "# Most recent UUID - Feb 1st, 2022 9:22AM\n",
    "func_id = '5f4461f7-a4e8-4c4d-addc-f20cf447b409'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a FuncX function\n",
    "\n",
    "All that is left to do now is to start the function and produce data. Notice that there is a parameter for `worker_id`. It is possible to start any number of the same FuncX function to run concurrently. Combining this with Kafka's ability to group consumers via their ID, we can spin up multiple instances of an analysis task to share the data messages. The `worker_id` parameter is used so that we can see which instance produced the results message. The way in which messaged are shared between consumers is an artifact of Kafka's partitioning of topics but is beyond the scope of this tutorial.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "press enter to check status again\n",
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "Task is pending due to waiting-for-ep\n",
      "press enter to check status again\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "press enter to check status again\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "Task is pending due to waiting-for-launch\n",
      "press enter to check status again\n",
      "Task is pending due to running\n",
      "Task is pending due to running\n",
      "Task is pending due to running\n",
      "press enter to check status again\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_483/615859666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"press enter to check status again\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mdml/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mdml/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "num_workers = 3\n",
    "tasks = []\n",
    "\n",
    "for i in range(num_workers):\n",
    "    params = {\n",
    "        'data_topic': 'mdml-testing-funcx-tutorial-data',\n",
    "        'control_topic': 'mdml-testing-funcx-tutorial-stop',\n",
    "        'addition_values': ['int1','int2','int3'],\n",
    "        'worker_id': i\n",
    "    }\n",
    "    endp_id = 'fa1a5d62-86f1-4761-87d5-0a2976a3e1c5' # public mdml endpoint on GPU server\n",
    "    tasks.append(fxc.run(params, function_id=func_id, endpoint_id=endp_id))\n",
    "\n",
    "while True:\n",
    "    for task in tasks:\n",
    "        try:\n",
    "            result = fxc.get_result(task)\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    input(f\"press enter to check status again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer loop will run indefinitely until a Ctrl+C\n",
      "{'topic': 'mdml-testing-funcx-tutorial-sum', 'value': {'time': 1643651363.290894, 'int1': 26, 'int2': 8, 'int3': 61, 'mdml_time': 1643651364.3562765, 'sum': 95}}\n",
      "{'topic': 'mdml-testing-funcx-tutorial-sum', 'value': {'time': 1643651369.3361378, 'int1': 97, 'int2': 23, 'int3': 71, 'mdml_time': 1643651369.4128666, 'sum': 191}}\n",
      "{'topic': 'mdml-testing-funcx-tutorial-sum', 'value': {'time': 1643651394.1517346, 'int1': 8, 'int2': 2, 'int3': 21, 'mdml_time': 1643651395.2494736, 'sum': 31}}\n"
     ]
    }
   ],
   "source": [
    "# Consume function results\n",
    "consumer = mdml.kafka_mdml_consumer(\n",
    "    topics = ['mdml-testing-funcx-tutorial-sum'],\n",
    "    group = \"mdml-testing-funcx-tutorial\")\n",
    "for msg in consumer.consume(overall_timeout=-1):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop FuncX worker\n",
    "producer = mdml.kafka_mdml_producer(topic=\"mdml-testing-funcx-tutorial-stop\",\n",
    "             schema=mdml.stop_funcx_schema)\n",
    "producer.produce({'stop':True})\n",
    "producer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdml",
   "language": "python",
   "name": "mdml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
